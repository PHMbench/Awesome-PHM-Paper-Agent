@article{faultformer2024pretraining,
  title={FaultFormer: Pretraining Transformers for Adaptable Bearing Fault Classification},
  author={Authors pending full verification},
  journal={arXiv preprint arXiv:2312.02380},
  year={2024},
  arxiv={2312.02380v2},
  keywords={Transformer, Pre-training, Bearing fault classification, Foundation models, Adaptable learning},
  abstract={FaultFormer introduces a pre-training approach for transformers in bearing fault classification, enabling adaptable classification across different operational domains through foundation model techniques.},
  note={Pre-training approach for adaptable fault classification}
}