"""
Paper Quality Filter - æ–‡çŒ®è´¨é‡è¿‡æ»¤å™¨

This module provides comprehensive quality filtering for academic papers,
including publisher filtering, impact factor requirements, journal quartiles,
and PHM domain-specific criteria.

Created: 2025-08-23
"""

import re
import yaml
from typing import Dict, List, Any, Optional, Tuple, Set
from pathlib import Path
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)


@dataclass
class FilterCriteria:
    """è´¨é‡è¿‡æ»¤æ ‡å‡†é…ç½®"""
    exclude_publishers: List[str] = None
    include_publishers: List[str] = None
    min_impact_factor: float = 0.0
    min_quartile: str = "Q4"  # Q1, Q2, Q3, Q4
    min_citation_count: int = 0
    phm_relevance_threshold: float = 0.0
    allow_preprints: bool = True
    custom_rules: List[Dict[str, Any]] = None
    
    def __post_init__(self):
        if self.exclude_publishers is None:
            self.exclude_publishers = []
        if self.include_publishers is None:
            self.include_publishers = []
        if self.custom_rules is None:
            self.custom_rules = []


class PaperQualityFilter:
    """
    æ–‡çŒ®è´¨é‡è¿‡æ»¤å™¨
    
    æä¾›å¤šç»´åº¦çš„è®ºæ–‡è´¨é‡è¯„ä¼°å’Œè¿‡æ»¤åŠŸèƒ½ï¼Œæ”¯æŒå‡ºç‰ˆå•†è¿‡æ»¤ã€
    å½±å“å› å­è¦æ±‚ã€æœŸåˆŠåˆ†çº§ã€PHMç›¸å…³æ€§ç­‰å¤šç§æ ‡å‡†ã€‚
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–è´¨é‡è¿‡æ»¤å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config_path = config_path
        self.load_configuration()
        
        # é¢„å®šä¹‰çš„å‡ºç‰ˆå•†ä¿¡æ¯
        self._load_publisher_database()
        
        # é¢„å®šä¹‰çš„æœŸåˆŠä¿¡æ¯
        self._load_journal_database()
    
    def load_configuration(self):
        """åŠ è½½è¿‡æ»¤é…ç½®"""
        if self.config_path and Path(self.config_path).exists():
            with open(self.config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
        else:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            self.config = self._get_default_config()
        
        logger.info(f"Loaded quality filter configuration")
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤è¿‡æ»¤é…ç½®"""
        return {
            'quality_filters': {
                'publisher_blacklist': [
                    'mdpi',
                    'hindawi', 
                    'bentham science',
                    'omics international',
                    'scientific research publishing',
                    'scirp',
                    'insight medical publishing'
                ],
                'publisher_whitelist': [
                    'ieee',
                    'elsevier',
                    'springer',
                    'nature publishing group',
                    'science',
                    'wiley',
                    'taylor & francis',
                    'american chemical society',
                    'american physical society',
                    'optical society of america'
                ],
                'impact_factor': {
                    'minimum': 3.0,
                    'preferred': 5.0,
                    'excellent': 8.0
                },
                'quartile': {
                    'minimum': 'Q3',
                    'preferred': 'Q2',
                    'excellent': 'Q1'
                },
                'phm_specific': {
                    'relevance_threshold': 0.6,
                    'core_venues': [
                        'Mechanical Systems and Signal Processing',
                        'IEEE Transactions on Industrial Electronics',
                        'Reliability Engineering & System Safety',
                        'Expert Systems with Applications',
                        'Applied Soft Computing',
                        'Knowledge-Based Systems',
                        'IEEE Transactions on Reliability',
                        'ISA Transactions',
                        'Measurement',
                        'Sensors',
                        'Neurocomputing'
                    ]
                }
            }
        }
    
    def _load_publisher_database(self):
        """åŠ è½½å‡ºç‰ˆå•†æ•°æ®åº“"""
        self.publisher_info = {
            # çŸ¥åå‡ºç‰ˆå•†åŠå…¶è¯„çº§
            'ieee': {'rating': 'excellent', 'type': 'technical_society'},
            'elsevier': {'rating': 'excellent', 'type': 'commercial'},
            'springer': {'rating': 'excellent', 'type': 'commercial'},
            'nature publishing group': {'rating': 'excellent', 'type': 'commercial'},
            'wiley': {'rating': 'excellent', 'type': 'commercial'},
            'taylor & francis': {'rating': 'good', 'type': 'commercial'},
            
            # è´¨é‡æœ‰äº‰è®®çš„å‡ºç‰ˆå•†
            'mdpi': {'rating': 'questionable', 'type': 'open_access', 'note': 'Quality varies by journal'},
            'hindawi': {'rating': 'questionable', 'type': 'open_access', 'note': 'Some quality concerns'},
            'bentham science': {'rating': 'poor', 'type': 'commercial', 'note': 'Known predatory practices'},
            'omics international': {'rating': 'poor', 'type': 'commercial', 'note': 'Predatory publisher'},
        }
    
    def _load_journal_database(self):
        """åŠ è½½æœŸåˆŠæ•°æ®åº“"""
        self.journal_info = {
            # PHMæ ¸å¿ƒæœŸåˆŠ
            'mechanical systems and signal processing': {
                'impact_factor': 8.4, 'quartile': 'Q1', 'category': 'engineering',
                'phm_relevance': 1.0, 'publisher': 'elsevier'
            },
            'ieee transactions on industrial electronics': {
                'impact_factor': 8.2, 'quartile': 'Q1', 'category': 'engineering',
                'phm_relevance': 0.9, 'publisher': 'ieee'
            },
            'reliability engineering & system safety': {
                'impact_factor': 7.6, 'quartile': 'Q1', 'category': 'engineering',
                'phm_relevance': 1.0, 'publisher': 'elsevier'
            },
            'expert systems with applications': {
                'impact_factor': 8.5, 'quartile': 'Q1', 'category': 'computer_science',
                'phm_relevance': 0.7, 'publisher': 'elsevier'
            },
            'applied soft computing': {
                'impact_factor': 8.7, 'quartile': 'Q1', 'category': 'computer_science',
                'phm_relevance': 0.6, 'publisher': 'elsevier'
            },
            'knowledge-based systems': {
                'impact_factor': 8.8, 'quartile': 'Q1', 'category': 'computer_science',
                'phm_relevance': 0.6, 'publisher': 'elsevier'
            },
            'ieee transactions on reliability': {
                'impact_factor': 5.9, 'quartile': 'Q1', 'category': 'engineering',
                'phm_relevance': 1.0, 'publisher': 'ieee'
            },
            'isa transactions': {
                'impact_factor': 7.3, 'quartile': 'Q1', 'category': 'engineering',
                'phm_relevance': 0.8, 'publisher': 'elsevier'
            },
            'measurement': {
                'impact_factor': 5.6, 'quartile': 'Q1', 'category': 'engineering',
                'phm_relevance': 0.7, 'publisher': 'elsevier'
            },
            'sensors': {
                'impact_factor': 3.9, 'quartile': 'Q2', 'category': 'engineering',
                'phm_relevance': 0.8, 'publisher': 'mdpi'
            },
            'neurocomputing': {
                'impact_factor': 6.0, 'quartile': 'Q1', 'category': 'computer_science',
                'phm_relevance': 0.5, 'publisher': 'elsevier'
            }
        }
    
    def filter_papers(self, papers: List[Dict[str, Any]], 
                     criteria: Optional[FilterCriteria] = None) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """
        è¿‡æ»¤è®ºæ–‡åˆ—è¡¨
        
        Args:
            papers: è®ºæ–‡å…ƒæ•°æ®åˆ—è¡¨
            criteria: è¿‡æ»¤æ ‡å‡†ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
            
        Returns:
            (filtered_papers, filter_report) è¿‡æ»¤åçš„è®ºæ–‡åˆ—è¡¨å’Œè¿‡æ»¤æŠ¥å‘Š
        """
        if criteria is None:
            criteria = self._get_default_filter_criteria()
        
        filtered_papers = []
        filter_report = {
            'total_papers': len(papers),
            'filtered_papers': 0,
            'filter_reasons': {},
            'quality_distribution': {},
            'publisher_distribution': {},
            'statistics': {}
        }
        
        for paper in papers:
            # è¯„ä¼°è®ºæ–‡è´¨é‡
            quality_assessment = self.assess_paper_quality(paper)
            
            # åº”ç”¨è¿‡æ»¤æ ‡å‡†
            filter_result = self._apply_filter_criteria(paper, quality_assessment, criteria)
            
            if filter_result['passed']:
                # æ·»åŠ è´¨é‡è¯„ä¼°ä¿¡æ¯åˆ°è®ºæ–‡å…ƒæ•°æ®
                paper['quality_assessment'] = quality_assessment
                paper['filter_score'] = filter_result['score']
                filtered_papers.append(paper)
            else:
                # è®°å½•è¿‡æ»¤åŸå› 
                for reason in filter_result['reasons']:
                    filter_report['filter_reasons'][reason] = filter_report['filter_reasons'].get(reason, 0) + 1
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        filter_report['filtered_papers'] = len(filtered_papers)
        filter_report['filter_rate'] = (len(papers) - len(filtered_papers)) / len(papers) if papers else 0
        
        # æŒ‰è´¨é‡åˆ†æ•°æ’åº
        filtered_papers.sort(key=lambda x: x.get('filter_score', 0), reverse=True)
        
        logger.info(f"Filtered {len(papers)} papers to {len(filtered_papers)} papers ({filter_report['filter_rate']:.2%} filtered out)")
        
        return filtered_papers, filter_report
    
    def assess_paper_quality(self, paper: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¯„ä¼°å•ç¯‡è®ºæ–‡çš„è´¨é‡
        
        Args:
            paper: è®ºæ–‡å…ƒæ•°æ®
            
        Returns:
            è´¨é‡è¯„ä¼°ç»“æœ
        """
        assessment = {
            'overall_score': 0.0,
            'venue_score': 0.0,
            'publisher_score': 0.0,
            'impact_score': 0.0,
            'citation_score': 0.0,
            'phm_relevance_score': 0.0,
            'quality_tier': 'unknown',
            'warnings': [],
            'strengths': []
        }
        
        # è·å–åŸºæœ¬ä¿¡æ¯
        venue = paper.get('venue', '').lower().strip()
        publisher = self._extract_publisher(paper)
        impact_factor = paper.get('impact_factor', 0.0)
        citation_count = paper.get('citation_count', 0)
        phm_relevance = paper.get('phm_relevance_score', 0.0)
        year = paper.get('year', 2024)
        
        # 1. æœŸåˆŠ/ä¼šè®®è¯„åˆ† (40%)
        venue_info = self.journal_info.get(venue, {})
        if venue_info:
            assessment['venue_score'] = self._calculate_venue_score(venue_info)
            if venue_info.get('quartile') == 'Q1':
                assessment['strengths'].append('Published in Q1 journal')
        else:
            assessment['warnings'].append('Unknown venue quality')
        
        # 2. å‡ºç‰ˆå•†è¯„åˆ† (20%)
        if publisher:
            publisher_info = self.publisher_info.get(publisher.lower(), {})
            assessment['publisher_score'] = self._calculate_publisher_score(publisher_info)
            if publisher_info.get('rating') == 'excellent':
                assessment['strengths'].append('Excellent publisher')
            elif publisher_info.get('rating') in ['questionable', 'poor']:
                assessment['warnings'].append(f'Publisher quality concern: {publisher_info.get("note", "")}')
        
        # 3. å½±å“å› å­è¯„åˆ† (15%)
        assessment['impact_score'] = self._calculate_impact_score(impact_factor)
        if impact_factor >= 8.0:
            assessment['strengths'].append('High impact factor')
        elif impact_factor < 3.0:
            assessment['warnings'].append('Low impact factor')
        
        # 4. å¼•ç”¨æ•°è¯„åˆ† (15%)
        assessment['citation_score'] = self._calculate_citation_score(citation_count, year)
        if citation_count > 100:
            assessment['strengths'].append('High citation count')
        
        # 5. PHMç›¸å…³æ€§è¯„åˆ† (10%)
        assessment['phm_relevance_score'] = phm_relevance
        if phm_relevance >= 0.8:
            assessment['strengths'].append('High PHM relevance')
        elif phm_relevance < 0.5:
            assessment['warnings'].append('Low PHM relevance')
        
        # è®¡ç®—æ€»åˆ†
        assessment['overall_score'] = (
            assessment['venue_score'] * 0.4 +
            assessment['publisher_score'] * 0.2 +
            assessment['impact_score'] * 0.15 +
            assessment['citation_score'] * 0.15 +
            assessment['phm_relevance_score'] * 0.1
        )
        
        # ç¡®å®šè´¨é‡ç­‰çº§
        assessment['quality_tier'] = self._determine_quality_tier(assessment['overall_score'])
        
        return assessment
    
    def _calculate_venue_score(self, venue_info: Dict[str, Any]) -> float:
        """è®¡ç®—æœŸåˆŠ/ä¼šè®®è¯„åˆ†"""
        if not venue_info:
            return 0.2
        
        quartile = venue_info.get('quartile', 'Q4')
        if quartile == 'Q1':
            return 1.0
        elif quartile == 'Q2':
            return 0.8
        elif quartile == 'Q3':
            return 0.6
        else:
            return 0.4
    
    def _calculate_publisher_score(self, publisher_info: Dict[str, Any]) -> float:
        """è®¡ç®—å‡ºç‰ˆå•†è¯„åˆ†"""
        if not publisher_info:
            return 0.5
        
        rating = publisher_info.get('rating', 'unknown')
        if rating == 'excellent':
            return 1.0
        elif rating == 'good':
            return 0.8
        elif rating == 'questionable':
            return 0.4
        elif rating == 'poor':
            return 0.1
        else:
            return 0.5
    
    def _calculate_impact_score(self, impact_factor: float) -> float:
        """è®¡ç®—å½±å“å› å­è¯„åˆ†"""
        if impact_factor >= 8.0:
            return 1.0
        elif impact_factor >= 5.0:
            return 0.8
        elif impact_factor >= 3.0:
            return 0.6
        elif impact_factor >= 1.0:
            return 0.4
        else:
            return 0.2
    
    def _calculate_citation_score(self, citation_count: int, year: int) -> float:
        """è®¡ç®—å¼•ç”¨æ•°è¯„åˆ†ï¼ˆè€ƒè™‘æ—¶é—´å› ç´ ï¼‰"""
        current_year = 2024
        age = current_year - year
        
        # æ ¹æ®è®ºæ–‡å¹´é¾„è°ƒæ•´æœŸæœ›å¼•ç”¨æ•°
        if age <= 1:
            expected_citations = 5
        elif age <= 2:
            expected_citations = 15
        elif age <= 5:
            expected_citations = 30
        else:
            expected_citations = 50
        
        ratio = citation_count / expected_citations
        return min(ratio, 1.0)
    
    def _determine_quality_tier(self, score: float) -> str:
        """ç¡®å®šè´¨é‡ç­‰çº§"""
        if score >= 0.85:
            return 'excellent'
        elif score >= 0.70:
            return 'good'
        elif score >= 0.55:
            return 'acceptable'
        elif score >= 0.40:
            return 'questionable'
        else:
            return 'poor'
    
    def _extract_publisher(self, paper: Dict[str, Any]) -> Optional[str]:
        """ä»è®ºæ–‡ä¿¡æ¯ä¸­æå–å‡ºç‰ˆå•†"""
        # ç›´æ¥ä»å…ƒæ•°æ®è·å–
        if 'publisher' in paper:
            return paper['publisher']
        
        # ä»æœŸåˆŠåç§°æ¨æ–­
        venue = paper.get('venue', '').lower()
        
        if 'ieee' in venue:
            return 'ieee'
        elif any(keyword in venue for keyword in ['elsevier', 'science direct']):
            return 'elsevier'
        elif 'springer' in venue:
            return 'springer'
        elif 'nature' in venue:
            return 'nature publishing group'
        elif 'wiley' in venue:
            return 'wiley'
        elif 'mdpi' in venue:
            return 'mdpi'
        elif 'hindawi' in venue:
            return 'hindawi'
        
        # ä»DOIæ¨æ–­
        doi = paper.get('doi', '')
        if doi:
            if '10.1109' in doi:
                return 'ieee'
            elif '10.1016' in doi:
                return 'elsevier'
            elif '10.1007' in doi:
                return 'springer'
            elif '10.1038' in doi:
                return 'nature publishing group'
            elif '10.3390' in doi:
                return 'mdpi'
        
        return None
    
    def _apply_filter_criteria(self, paper: Dict[str, Any], 
                              assessment: Dict[str, Any], 
                              criteria: FilterCriteria) -> Dict[str, Any]:
        """åº”ç”¨è¿‡æ»¤æ ‡å‡†"""
        result = {
            'passed': True,
            'reasons': [],
            'score': assessment['overall_score']
        }
        
        publisher = self._extract_publisher(paper)
        venue = paper.get('venue', '').lower()
        impact_factor = paper.get('impact_factor', 0.0)
        quartile = assessment.get('venue_score', 0.0)
        citation_count = paper.get('citation_count', 0)
        phm_relevance = paper.get('phm_relevance_score', 0.0)
        paper_type = paper.get('venue_type', paper.get('type', 'journal'))
        
        # 1. å‡ºç‰ˆå•†é»‘åå•æ£€æŸ¥
        if publisher and publisher.lower() in [p.lower() for p in criteria.exclude_publishers]:
            result['passed'] = False
            result['reasons'].append(f'Excluded publisher: {publisher}')
        
        # 2. å‡ºç‰ˆå•†ç™½åå•æ£€æŸ¥ï¼ˆå¦‚æœæŒ‡å®šäº†ç™½åå•ï¼‰
        if criteria.include_publishers and publisher:
            if publisher.lower() not in [p.lower() for p in criteria.include_publishers]:
                result['passed'] = False
                result['reasons'].append(f'Not in approved publisher list: {publisher}')
        
        # 3. å½±å“å› å­æ£€æŸ¥
        if impact_factor > 0 and impact_factor < criteria.min_impact_factor:
            result['passed'] = False
            result['reasons'].append(f'Impact factor {impact_factor} below minimum {criteria.min_impact_factor}')
        
        # 4. æœŸåˆŠåˆ†çº§æ£€æŸ¥
        quartile_scores = {'Q1': 1.0, 'Q2': 0.8, 'Q3': 0.6, 'Q4': 0.4}
        min_quartile_score = quartile_scores.get(criteria.min_quartile, 0.0)
        if assessment['venue_score'] < min_quartile_score:
            result['passed'] = False
            result['reasons'].append(f'Journal quality below {criteria.min_quartile}')
        
        # 5. å¼•ç”¨æ•°æ£€æŸ¥
        if citation_count < criteria.min_citation_count:
            result['passed'] = False
            result['reasons'].append(f'Citation count {citation_count} below minimum {criteria.min_citation_count}')
        
        # 6. PHMç›¸å…³æ€§æ£€æŸ¥
        if phm_relevance < criteria.phm_relevance_threshold:
            result['passed'] = False
            result['reasons'].append(f'PHM relevance {phm_relevance:.2f} below threshold {criteria.phm_relevance_threshold}')
        
        # 7. é¢„å°æœ¬æ£€æŸ¥
        if not criteria.allow_preprints and paper_type in ['preprint', 'arxiv']:
            result['passed'] = False
            result['reasons'].append('Preprints not allowed')
        
        # 8. è‡ªå®šä¹‰è§„åˆ™æ£€æŸ¥
        for rule in criteria.custom_rules:
            if self._evaluate_custom_rule(paper, assessment, rule):
                if rule.get('action') == 'exclude':
                    result['passed'] = False
                    result['reasons'].append(f'Custom rule: {rule.get("name", "unnamed rule")}')
                elif rule.get('action') == 'boost':
                    result['score'] += rule.get('boost_amount', 0.1)
        
        return result
    
    def _evaluate_custom_rule(self, paper: Dict[str, Any], 
                             assessment: Dict[str, Any], 
                             rule: Dict[str, Any]) -> bool:
        """è¯„ä¼°è‡ªå®šä¹‰è§„åˆ™"""
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„è§„åˆ™é€»è¾‘
        # ç›®å‰ç®€å•å®ç°åŸºäºæ¡ä»¶å­—ç¬¦ä¸²çš„è¯„ä¼°
        condition = rule.get('condition', '')
        
        # ç®€åŒ–çš„æ¡ä»¶è¯„ä¼°ï¼ˆå®é™…å®ç°å¯ä»¥æ›´å¤æ‚ï¼‰
        if 'citation_count >' in condition:
            threshold = int(re.search(r'citation_count > (\d+)', condition).group(1))
            return paper.get('citation_count', 0) > threshold
        
        return False
    
    def _get_default_filter_criteria(self) -> FilterCriteria:
        """è·å–é»˜è®¤è¿‡æ»¤æ ‡å‡†"""
        config = self.config.get('quality_filters', {})
        
        return FilterCriteria(
            exclude_publishers=config.get('publisher_blacklist', []),
            include_publishers=config.get('publisher_whitelist', []),
            min_impact_factor=config.get('impact_factor', {}).get('minimum', 0.0),
            min_quartile=config.get('quartile', {}).get('minimum', 'Q4'),
            min_citation_count=0,
            phm_relevance_threshold=config.get('phm_specific', {}).get('relevance_threshold', 0.0),
            allow_preprints=True
        )
    
    def get_filter_summary(self, filter_report: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¿‡æ»¤æ‘˜è¦æŠ¥å‘Š"""
        total = filter_report['total_papers']
        filtered = filter_report['filtered_papers']
        filter_rate = filter_report['filter_rate']
        
        summary = f"ğŸ“Š è´¨é‡è¿‡æ»¤æŠ¥å‘Š\n"
        summary += f"æ€»è®ºæ–‡æ•°: {total}\n"
        summary += f"é€šè¿‡è¿‡æ»¤: {filtered}\n"
        summary += f"è¿‡æ»¤ç‡: {filter_rate:.1%}\n\n"
        
        if filter_report['filter_reasons']:
            summary += "ä¸»è¦è¿‡æ»¤åŸå› :\n"
            for reason, count in sorted(filter_report['filter_reasons'].items(), 
                                      key=lambda x: x[1], reverse=True):
                summary += f"  - {reason}: {count}ç¯‡\n"
        
        return summary


def create_filter_with_config(**kwargs) -> PaperQualityFilter:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºå¸¦æœ‰æŒ‡å®šé…ç½®çš„è¿‡æ»¤å™¨
    
    Args:
        **kwargs: è¿‡æ»¤é…ç½®å‚æ•°
        
    Returns:
        é…ç½®å¥½çš„è´¨é‡è¿‡æ»¤å™¨å®ä¾‹
    """
    filter_obj = PaperQualityFilter()
    
    # æ›´æ–°é…ç½®
    if kwargs:
        config_updates = {'quality_filters': kwargs}
        filter_obj.config.update(config_updates)
    
    return filter_obj


# ä¾¿æ·å‡½æ•°ï¼šå¸¸ç”¨è¿‡æ»¤å™¨é…ç½®
def create_strict_filter() -> PaperQualityFilter:
    """åˆ›å»ºä¸¥æ ¼çš„è´¨é‡è¿‡æ»¤å™¨"""
    return create_filter_with_config(
        publisher_blacklist=['mdpi', 'hindawi', 'bentham science'],
        impact_factor={'minimum': 5.0},
        quartile={'minimum': 'Q2'},
        phm_specific={'relevance_threshold': 0.7}
    )


def create_moderate_filter() -> PaperQualityFilter:
    """åˆ›å»ºä¸­ç­‰ä¸¥æ ¼çš„è´¨é‡è¿‡æ»¤å™¨"""
    return create_filter_with_config(
        publisher_blacklist=['bentham science', 'omics international'],
        impact_factor={'minimum': 3.0},
        quartile={'minimum': 'Q3'},
        phm_specific={'relevance_threshold': 0.5}
    )


def create_permissive_filter() -> PaperQualityFilter:
    """åˆ›å»ºå®½æ¾çš„è´¨é‡è¿‡æ»¤å™¨"""
    return create_filter_with_config(
        publisher_blacklist=['omics international'],
        impact_factor={'minimum': 1.0},
        quartile={'minimum': 'Q4'},
        phm_specific={'relevance_threshold': 0.3}
    )


if __name__ == "__main__":
    # æµ‹è¯•è´¨é‡è¿‡æ»¤å™¨
    test_papers = [
        {
            'title': 'Deep Learning for Bearing Fault Diagnosis',
            'venue': 'Mechanical Systems and Signal Processing',
            'impact_factor': 8.4,
            'citation_count': 150,
            'phm_relevance_score': 0.95,
            'year': 2023
        },
        {
            'title': 'Some Random Study',
            'venue': 'Random MDPI Journal',
            'impact_factor': 2.1,
            'citation_count': 5,
            'phm_relevance_score': 0.3,
            'year': 2024,
            'publisher': 'mdpi'
        }
    ]
    
    # æµ‹è¯•ä¸åŒä¸¥æ ¼ç¨‹åº¦çš„è¿‡æ»¤å™¨
    for filter_name, filter_func in [
        ('Strict', create_strict_filter),
        ('Moderate', create_moderate_filter), 
        ('Permissive', create_permissive_filter)
    ]:
        print(f"\n=== {filter_name} Filter Test ===")
        filter_obj = filter_func()
        filtered_papers, report = filter_obj.filter_papers(test_papers)
        print(f"Filtered {len(test_papers)} -> {len(filtered_papers)} papers")
        print(filter_obj.get_filter_summary(report))