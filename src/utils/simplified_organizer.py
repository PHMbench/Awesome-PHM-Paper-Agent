"""
Simplified Knowledge Organizer

è¿™ä¸ªæ¨¡å—åˆ›å»ºç²¾ç®€ç‰ˆçš„è®ºæ–‡çŸ¥è¯†åº“ï¼ŒåªåŒ…å«æ ¸å¿ƒä¿¡æ¯ï¼š
- æ ‡é¢˜
- ä½œè€…å’Œå•ä½
- æ‘˜è¦
- BibTeX å¼•ç”¨

ä¸åŒ…å«å†—ä½™çš„ç»Ÿè®¡ä¿¡æ¯ã€å¤æ‚çš„å¯¼èˆªæˆ–è¿‡å¤šçš„å…ƒæ•°æ®ã€‚
"""

import os
import re
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
from collections import defaultdict

from .logging_config import get_logger


class SimplifiedPaperOrganizer:
    """
    ç®€åŒ–çš„è®ºæ–‡ç»„ç»‡å™¨
    
    åªç”Ÿæˆå¿…è¦çš„æ–‡ä»¶å’Œä¿¡æ¯ï¼Œä¸“æ³¨äºæ ¸å¿ƒå†…å®¹ï¼š
    - ç®€æ´çš„è®ºæ–‡é¡µé¢ï¼ˆæ ‡é¢˜ã€ä½œè€…ã€å•ä½ã€æ‘˜è¦ï¼‰
    - åŸºæœ¬çš„åˆ†ç±»ç´¢å¼•
    - æ¸…æ™°çš„ BibTeX å¼•ç”¨
    """
    
    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.logger = get_logger(__name__)
        
        # ç®€åŒ–çš„ PHM åˆ†ç±»
        self.categories = {
            'deep-learning': {
                'title': 'Deep Learning in PHM',
                'keywords': ['deep learning', 'neural network', 'CNN', 'LSTM', 'transformer']
            },
            'fault-diagnosis': {
                'title': 'Fault Diagnosis & Detection', 
                'keywords': ['fault diagnosis', 'fault detection', 'anomaly detection', 'bearing fault']
            },
            'rul-prediction': {
                'title': 'Remaining Useful Life Prediction',
                'keywords': ['RUL', 'remaining useful life', 'prognostics', 'degradation']
            },
            'digital-twin': {
                'title': 'Digital Twin for PHM',
                'keywords': ['digital twin', 'cyber-physical', 'virtual sensor']
            },
            'predictive-maintenance': {
                'title': 'Predictive Maintenance',
                'keywords': ['predictive maintenance', 'condition monitoring', 'maintenance']
            }
        }
        
        # åˆå§‹åŒ–ç›®å½•ç»“æ„
        self._init_directories()
        
        self.logger.info("Simplified Paper Organizer initialized")
    
    def _init_directories(self):
        """åˆå§‹åŒ–ç®€åŒ–çš„ç›®å½•ç»“æ„"""
        
        directories = [
            'categories',
            'papers',
            'by-year'
        ]
        
        for category in self.categories:
            directories.append(f'categories/{category}')
        
        for dir_path in directories:
            (self.base_path / dir_path).mkdir(parents=True, exist_ok=True)
    
    def organize_papers(self, papers: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ç»„ç»‡è®ºæ–‡åˆ°ç®€åŒ–çš„çŸ¥è¯†åº“ç»“æ„
        
        Args:
            papers: è®ºæ–‡ä¿¡æ¯åˆ—è¡¨
            
        Returns:
            ç»„ç»‡ç»“æœæ‘˜è¦
        """
        
        self.logger.info(f"Organizing {len(papers)} papers with simplified structure")
        
        if not papers:
            self.logger.warning("No papers to organize")
            return {'status': 'no_papers'}
        
        # åˆ†ç±»è®ºæ–‡
        categorized = self._categorize_papers(papers)
        
        # ç”Ÿæˆè®ºæ–‡é¡µé¢
        paper_files = self._generate_paper_pages(papers)
        
        # ç”Ÿæˆåˆ†ç±»é¡µé¢
        category_files = self._generate_category_pages(categorized)
        
        # ç”Ÿæˆä¸»é¡µ
        main_readme = self._generate_main_readme(papers, categorized)
        
        # ç”Ÿæˆå¹´ä»½ç´¢å¼•
        year_index = self._generate_year_index(papers)
        
        summary = {
            'status': 'completed',
            'total_papers': len(papers),
            'categories': len(categorized),
            'files_created': len(paper_files) + len(category_files) + 2,  # +2 for main README and year index
            'organization_date': datetime.now().isoformat(),
            'simplified_structure': True
        }
        
        self.logger.info(f"Organization complete: {summary}")
        return summary
    
    def _categorize_papers(self, papers: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """ç®€åŒ–çš„è®ºæ–‡åˆ†ç±»"""
        
        categorized = defaultdict(list)
        
        for paper in papers:
            # åˆ†æè®ºæ–‡å†…å®¹ç¡®å®šåˆ†ç±»
            paper_categories = self._analyze_paper_category(paper)
            primary_category = paper_categories[0] if paper_categories else 'predictive-maintenance'
            
            categorized[primary_category].append(paper)
            paper['primary_category'] = primary_category
        
        return dict(categorized)
    
    def _analyze_paper_category(self, paper: Dict[str, Any]) -> List[str]:
        """åˆ†æè®ºæ–‡åº”å±äºå“ªä¸ªç±»åˆ«"""
        
        # åˆå¹¶æ ‡é¢˜å’Œæ‘˜è¦è¿›è¡Œåˆ†æ
        content = (
            paper.get('title', '') + ' ' + 
            paper.get('abstract', '')
        ).lower()
        
        category_scores = {}
        
        for cat_id, cat_info in self.categories.items():
            score = 0
            for keyword in cat_info['keywords']:
                if keyword.lower() in content:
                    score += 1
            
            if score > 0:
                category_scores[cat_id] = score
        
        # æŒ‰åˆ†æ•°æ’åºè¿”å›
        sorted_categories = sorted(category_scores.items(), key=lambda x: x[1], reverse=True)
        return [cat for cat, score in sorted_categories]
    
    def _generate_paper_pages(self, papers: List[Dict[str, Any]]) -> List[str]:
        """ç”Ÿæˆç®€åŒ–çš„è®ºæ–‡é¡µé¢"""
        
        created_files = []
        
        for paper in papers:
            # åˆ›å»ºè®ºæ–‡æ–‡ä»¶å
            paper_filename = self._create_paper_filename(paper)
            paper_path = self.base_path / 'papers' / f"{paper_filename}.md"
            
            # ç”Ÿæˆç®€åŒ–çš„è®ºæ–‡å†…å®¹
            content = self._generate_simplified_paper_content(paper)
            
            with open(paper_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            created_files.append(str(paper_path))
        
        return created_files
    
    def _create_paper_filename(self, paper: Dict[str, Any]) -> str:
        """åˆ›å»ºè®ºæ–‡æ–‡ä»¶å"""
        
        year = paper.get('year', 'unknown')
        
        # è·å–ç¬¬ä¸€ä½œè€…å§“æ°
        authors = paper.get('authors', [])
        first_author = authors[0] if authors else 'Unknown'
        
        # æå–å§“æ°
        if ',' in first_author:
            # æ ¼å¼ï¼šå§“, å
            surname = first_author.split(',')[0].strip()
        else:
            # æ ¼å¼ï¼šå å§“
            parts = first_author.split()
            surname = parts[-1] if parts else 'Unknown'
        
        # æ¸…ç†æ ‡é¢˜è·å–å…³é”®è¯
        title = paper.get('title', 'Unknown')
        title_words = re.findall(r'\b\w+\b', title)[:3]  # å‰3ä¸ªå…³é”®è¯
        title_key = ''.join(word.capitalize() for word in title_words)
        
        # åˆ›å»ºæ–‡ä»¶å
        filename = f"{year}-{surname}-{title_key}"
        
        # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
        filename = re.sub(r'[^\w\-_]', '', filename)
        
        return filename[:50]  # é™åˆ¶é•¿åº¦
    
    def _generate_simplified_paper_content(self, paper: Dict[str, Any]) -> str:
        """ç”Ÿæˆç®€åŒ–çš„è®ºæ–‡é¡µé¢å†…å®¹"""
        
        title = paper.get('title', 'Unknown Title')
        authors = paper.get('authors', [])
        year = paper.get('year', 'Unknown')
        venue = paper.get('venue', 'Unknown Venue')
        abstract = paper.get('abstract', 'No abstract available')
        
        # æ ¼å¼åŒ–ä½œè€…å’Œå•ä½
        authors_formatted = self._format_authors_with_affiliations(authors)
        
        content = f"""# {title}

**ä½œè€…**: {authors_formatted}

**å‘è¡¨å¹´ä»½**: {year}

**æœŸåˆŠ/ä¼šè®®**: {venue}

## æ‘˜è¦

{abstract}

## å¼•ç”¨

```bibtex
{self._generate_bibtex(paper)}
```

---

*è®ºæ–‡é¡µé¢ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d')}*
"""
        
        return content
    
    def _format_authors_with_affiliations(self, authors: List[str]) -> str:
        """æ ¼å¼åŒ–ä½œè€…åˆ—è¡¨ï¼ˆå°è¯•åŒ…å«å•ä½ä¿¡æ¯ï¼‰"""
        
        if not authors:
            return "æœªçŸ¥ä½œè€…"
        
        # ç®€åŒ–å¤„ç†ï¼šç›´æ¥åˆ—å‡ºä½œè€…
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦ä»åŸå§‹æ•°æ®ä¸­æå–å•ä½ä¿¡æ¯
        if len(authors) <= 5:
            return ', '.join(authors)
        else:
            return ', '.join(authors[:5]) + ' ç­‰'
    
    def _generate_bibtex(self, paper: Dict[str, Any]) -> str:
        """ç”Ÿæˆ BibTeX å¼•ç”¨"""
        
        # åˆ›å»ºå¼•ç”¨é”®
        authors = paper.get('authors', ['Unknown'])
        first_author_lastname = authors[0].split()[-1] if authors else 'Unknown'
        year = paper.get('year', datetime.now().year)
        title_words = re.findall(r'\w+', paper.get('title', ''))[:2]
        title_key = ''.join(word.capitalize() for word in title_words)
        
        cite_key = f"{first_author_lastname}{year}{title_key}"
        
        # ç¡®å®šç±»å‹
        venue = paper.get('venue', '').lower()
        entry_type = 'article' if any(word in venue for word in ['journal', 'transactions']) else 'inproceedings'
        
        # æ„å»º BibTeX
        bibtex = f"@{entry_type}{{{cite_key},\n"
        bibtex += f'  title = {{{paper.get("title", "Unknown Title")}}},\n'
        
        if paper.get('authors'):
            author_str = ' and '.join(paper['authors'][:5])  # é™åˆ¶ä½œè€…æ•°é‡
            bibtex += f"  author = {{{author_str}}},\n"
        
        if paper.get('year'):
            bibtex += f"  year = {{{paper['year']}}},\n"
        
        if paper.get('venue'):
            venue_field = 'journal' if entry_type == 'article' else 'booktitle'
            bibtex += f"  {venue_field} = {{{paper['venue']}}},\n"
        
        if paper.get('doi'):
            bibtex += f"  doi = {{{paper['doi']}}},\n"
        
        bibtex += "}\n"
        
        return bibtex
    
    def _generate_category_pages(self, categorized: Dict[str, List[Dict[str, Any]]]) -> List[str]:
        """ç”Ÿæˆç®€åŒ–çš„åˆ†ç±»é¡µé¢"""
        
        created_files = []
        
        for category_id, papers in categorized.items():
            if category_id not in self.categories:
                continue
                
            category_info = self.categories[category_id]
            category_path = self.base_path / 'categories' / category_id / 'README.md'
            
            content = f"""# {category_info['title']}

å…± {len(papers)} ç¯‡è®ºæ–‡

## è®ºæ–‡åˆ—è¡¨

"""
            
            # æŒ‰å¹´ä»½é™åºæ’åˆ—
            sorted_papers = sorted(papers, key=lambda p: p.get('year', 0), reverse=True)
            
            for i, paper in enumerate(sorted_papers, 1):
                title = paper.get('title', 'Unknown Title')
                authors = paper.get('authors', [])
                year = paper.get('year', 'Unknown')
                
                # ä½œè€…æ ¼å¼åŒ–
                if len(authors) > 2:
                    author_str = f"{authors[0]} ç­‰"
                else:
                    author_str = ', '.join(authors)
                
                # åˆ›å»ºè®ºæ–‡é“¾æ¥
                paper_filename = self._create_paper_filename(paper)
                paper_link = f"../../papers/{paper_filename}.md"
                
                content += f"{i}. **[{title}]({paper_link})**\n"
                content += f"   - *{author_str}* ({year})\n\n"
            
            content += f"""
---

*åˆ†ç±»é¡µé¢æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d')}*
"""
            
            with open(category_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            created_files.append(str(category_path))
        
        return created_files
    
    def _generate_main_readme(self, 
                            papers: List[Dict[str, Any]], 
                            categorized: Dict[str, List[Dict[str, Any]]]) -> str:
        """ç”Ÿæˆç®€åŒ–çš„ä¸»é¡µ README"""
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_papers = len(papers)
        years = [p.get('year') for p in papers if p.get('year')]
        year_range = f"{min(years)}-{max(years)}" if years else "æœªçŸ¥"
        
        content = f"""# Awesome PHM Papers

> ç²¾é€‰çš„ PHM (é¢„æµ‹æ€§å¥åº·ç®¡ç†) å­¦æœ¯è®ºæ–‡é›†åˆ

æœ¬çŸ¥è¯†åº“æ”¶é›†äº† PHM é¢†åŸŸçš„é‡è¦å­¦æœ¯è®ºæ–‡ï¼Œæ‰€æœ‰è®ºæ–‡ä¿¡æ¯å‡æ¥è‡ªçœŸå®çš„å­¦æœ¯æ•°æ®åº“ã€‚

## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯

- **è®ºæ–‡æ€»æ•°**: {total_papers}
- **åˆ†ç±»æ•°é‡**: {len(categorized)}
- **å¹´ä»½èŒƒå›´**: {year_range}
- **æœ€åæ›´æ–°**: {datetime.now().strftime('%Y-%m-%d')}

## ğŸ“š æŒ‰ç±»åˆ«æµè§ˆ

"""
        
        for category_id, papers_in_cat in categorized.items():
            if category_id in self.categories:
                cat_title = self.categories[category_id]['title']
                content += f"- **[{cat_title}](categories/{category_id}/README.md)** ({len(papers_in_cat)} ç¯‡è®ºæ–‡)\n"
        
        content += f"""

## ğŸ“… æŒ‰å¹´ä»½æµè§ˆ

- [æŒ‰å¹´ä»½æŸ¥çœ‹è®ºæ–‡](by-year/README.md)

## ğŸ” æœ€æ–°è®ºæ–‡

"""
        
        # æ˜¾ç¤ºæœ€æ–°çš„5ç¯‡è®ºæ–‡
        recent_papers = sorted(papers, key=lambda p: p.get('year', 0), reverse=True)[:5]
        
        for i, paper in enumerate(recent_papers, 1):
            title = paper.get('title', 'Unknown Title')
            authors = paper.get('authors', [])
            year = paper.get('year', 'Unknown')
            
            author_str = authors[0] if authors else 'Unknown Author'
            if len(authors) > 1:
                author_str += ' ç­‰'
            
            paper_filename = self._create_paper_filename(paper)
            paper_link = f"papers/{paper_filename}.md"
            
            content += f"{i}. **[{title}]({paper_link})**\n"
            content += f"   - *{author_str}* ({year})\n\n"
        
        content += f"""
## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®æ–°çš„ PHM ç›¸å…³è®ºæ–‡ï¼è¯·ç¡®ä¿ï¼š

1. **çœŸå®è®ºæ–‡**: å¿…é¡»æ˜¯å·²å‘è¡¨æˆ–é¢„å°æœ¬çš„çœŸå®å­¦æœ¯è®ºæ–‡
2. **PHM ç›¸å…³**: ä¸é¢„æµ‹æ€§å¥åº·ç®¡ç†ç›¸å…³
3. **å®Œæ•´ä¿¡æ¯**: åŒ…å«æ ‡é¢˜ã€ä½œè€…ã€æ‘˜è¦ç­‰åŸºæœ¬ä¿¡æ¯

## ğŸ“„ è®¸å¯

æœ¬é¡¹ç›®é‡‡ç”¨ [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/) è®¸å¯åè®®ã€‚

---

*ç”± APPA (Awesome PHM Paper Agent) è‡ªåŠ¨ç”Ÿæˆå’Œç»´æŠ¤*
"""
        
        # å†™å…¥ä¸» README
        main_readme_path = self.base_path / 'README.md'
        with open(main_readme_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return str(main_readme_path)
    
    def _generate_year_index(self, papers: List[Dict[str, Any]]) -> str:
        """ç”ŸæˆæŒ‰å¹´ä»½çš„ç´¢å¼•"""
        
        # æŒ‰å¹´ä»½åˆ†ç»„
        papers_by_year = defaultdict(list)
        for paper in papers:
            year = paper.get('year', 'Unknown')
            papers_by_year[year].append(paper)
        
        content = """# æŒ‰å¹´ä»½æµè§ˆè®ºæ–‡

"""
        
        # æŒ‰å¹´ä»½é™åºæ’åˆ—
        for year in sorted(papers_by_year.keys(), reverse=True):
            year_papers = papers_by_year[year]
            content += f"\n## {year} ({len(year_papers)} ç¯‡è®ºæ–‡)\n\n"
            
            for paper in year_papers:
                title = paper.get('title', 'Unknown Title')
                authors = paper.get('authors', [])
                
                author_str = authors[0] if authors else 'Unknown Author'
                if len(authors) > 1:
                    author_str += ' ç­‰'
                
                paper_filename = self._create_paper_filename(paper)
                paper_link = f"../papers/{paper_filename}.md"
                
                content += f"- **[{title}]({paper_link})** - *{author_str}*\n"
        
        content += f"""

---

*å¹´ä»½ç´¢å¼•æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d')}*
"""
        
        # å†™å…¥å¹´ä»½ç´¢å¼•
        year_index_path = self.base_path / 'by-year' / 'README.md'
        with open(year_index_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return str(year_index_path)


if __name__ == "__main__":
    # æµ‹è¯•ç®€åŒ–ç»„ç»‡å™¨
    import tempfile
    import shutil
    
    test_dir = tempfile.mkdtemp()
    print(f"Testing in: {test_dir}")
    
    try:
        organizer = SimplifiedPaperOrganizer(test_dir)
        
        # æµ‹è¯•è®ºæ–‡
        test_papers = [
            {
                'title': 'Deep Learning for Bearing Fault Diagnosis',
                'authors': ['Zhang, Wei', 'Liu, Ming'],
                'year': 2024,
                'venue': 'Mechanical Systems and Signal Processing',
                'abstract': 'This paper presents a deep learning approach for bearing fault diagnosis using CNN-LSTM networks. The method achieves high accuracy in fault classification.',
                'doi': '10.1016/j.ymssp.2024.123456'
            },
            {
                'title': 'RUL Prediction Using LSTM Networks',
                'authors': ['Chen, Li', 'Wang, Jun'],
                'year': 2023,
                'venue': 'IEEE Transactions on Industrial Electronics',
                'abstract': 'A novel LSTM-based method for remaining useful life prediction of mechanical components is proposed and validated on real datasets.',
                'doi': '10.1109/TIE.2023.654321'
            }
        ]
        
        # æ‰§è¡Œç»„ç»‡
        result = organizer.organize_papers(test_papers)
        
        print(f"âœ… Organization successful!")
        print(f"   Papers: {result['total_papers']}")
        print(f"   Categories: {result['categories']}")
        print(f"   Files created: {result['files_created']}")
        
        # åˆ—å‡ºåˆ›å»ºçš„æ–‡ä»¶
        print(f"\nğŸ“ Created files:")
        for root, dirs, files in os.walk(test_dir):
            for file in files:
                rel_path = os.path.relpath(os.path.join(root, file), test_dir)
                print(f"   {rel_path}")
        
    finally:
        shutil.rmtree(test_dir)
        print(f"\nğŸ§¹ Cleaned up: {test_dir}")