#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Update Manager - ç”¨æˆ·ç¡®è®¤æ›´æ–°æœºåˆ¶
Update Manager - User Confirmation Mechanism for Updates

æ ¸å¿ƒåŠŸèƒ½ï¼š
- ç”Ÿæˆè®ºæ–‡æ›´æ–°ææ¡ˆä¾›ç”¨æˆ·ç¡®è®¤
- ç®¡ç†Awesomeåˆ—è¡¨çš„å¢é‡æ›´æ–°
- ç¡®ä¿ç”¨æˆ·å¯¹æ‰€æœ‰å†…å®¹æ›´æ–°æœ‰å®Œå…¨æ§åˆ¶æƒ
"""

import os
import json
import difflib
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path

from .logging_config import get_logger


class UpdateProposal:
    """æ›´æ–°ææ¡ˆç±»"""
    
    def __init__(self):
        self.timestamp = datetime.now().isoformat()
        self.new_papers: List[Dict[str, Any]] = []
        self.readme_changes: Dict[str, Any] = {}
        self.data_changes: Dict[str, Any] = {}
        self.quality_summary: Dict[str, Any] = {}
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'timestamp': self.timestamp,
            'new_papers': self.new_papers,
            'readme_changes': self.readme_changes,
            'data_changes': self.data_changes,
            'quality_summary': self.quality_summary
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'UpdateProposal':
        """ä»å­—å…¸åˆ›å»ºææ¡ˆ"""
        proposal = cls()
        proposal.timestamp = data.get('timestamp', proposal.timestamp)
        proposal.new_papers = data.get('new_papers', [])
        proposal.readme_changes = data.get('readme_changes', {})
        proposal.data_changes = data.get('data_changes', {})
        proposal.quality_summary = data.get('quality_summary', {})
        return proposal


class UpdateManager:
    """
    æ›´æ–°ç®¡ç†å™¨ - æ ¸å¿ƒç”¨æˆ·ç¡®è®¤æœºåˆ¶
    
    èŒè´£ï¼š
    1. åˆ†ææ–°å‘ç°çš„è®ºæ–‡
    2. ç”Ÿæˆç»“æ„åŒ–æ›´æ–°ææ¡ˆ
    3. æä¾›ç”¨æˆ·å‹å¥½çš„ç¡®è®¤ç•Œé¢
    4. ä»…åº”ç”¨ç”¨æˆ·ç¡®è®¤çš„æ›´æ–°
    """
    
    def __init__(self, project_root: str = "."):
        """
        åˆå§‹åŒ–æ›´æ–°ç®¡ç†å™¨
        
        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
        """
        self.project_root = Path(project_root)
        self.data_dir = self.project_root / "data"
        self.logger = get_logger(__name__)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self._ensure_directories()
    
    def _ensure_directories(self):
        """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        directories = [
            self.data_dir,
            self.data_dir / "papers",
            self.data_dir / "bibtex",
            self.data_dir / "abstracts",
            self.data_dir / "statistics",
            self.data_dir / "quality_scores",
            self.data_dir / "proposals"  # å­˜å‚¨æœªå†³ææ¡ˆ
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
    
    def generate_proposal(self, 
                         new_papers: List[Dict[str, Any]], 
                         search_context: Optional[Dict[str, Any]] = None) -> UpdateProposal:
        """
        ç”Ÿæˆæ›´æ–°ææ¡ˆ
        
        Args:
            new_papers: æ–°å‘ç°çš„è®ºæ–‡åˆ—è¡¨
            search_context: æœç´¢ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Returns:
            UpdateProposal: ç»“æ„åŒ–çš„æ›´æ–°ææ¡ˆ
        """
        self.logger.info(f"ç”Ÿæˆæ›´æ–°ææ¡ˆï¼ŒåŒ…å« {len(new_papers)} ç¯‡æ–°è®ºæ–‡")
        
        proposal = UpdateProposal()
        proposal.new_papers = new_papers
        
        # åˆ†æè®ºæ–‡è´¨é‡åˆ†å¸ƒ
        proposal.quality_summary = self._analyze_quality_distribution(new_papers)
        
        # ç”ŸæˆREADMEå˜æ›´é¢„è§ˆ
        proposal.readme_changes = self._generate_readme_changes(new_papers)
        
        # ç”Ÿæˆæ•°æ®æ–‡ä»¶å˜æ›´é¢„è§ˆ
        proposal.data_changes = self._generate_data_changes(new_papers)
        
        # ä¿å­˜ææ¡ˆä»¥å¤‡åç»­å¤„ç†
        self._save_proposal(proposal, search_context)
        
        return proposal
    
    def _analyze_quality_distribution(self, papers: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡è´¨é‡åˆ†å¸ƒ"""
        quality_stats = {
            'total_papers': len(papers),
            'by_tier': {'top_tier': 0, 'excellent': 0, 'good': 0, 'under_review': 0},
            'by_venue_type': {'journal': 0, 'conference': 0, 'preprint': 0},
            'by_year': {},
            'excluded_publishers': [],
            'high_impact_journals': []
        }
        
        for paper in papers:
            # è´¨é‡åˆ†çº§ç»Ÿè®¡
            tier = paper.get('quality_tier', 'under_review')
            if tier in quality_stats['by_tier']:
                quality_stats['by_tier'][tier] += 1
            
            # å‘è¡¨ç±»å‹ç»Ÿè®¡
            venue_type = paper.get('venue_type', 'unknown')
            if venue_type in quality_stats['by_venue_type']:
                quality_stats['by_venue_type'][venue_type] += 1
            
            # å¹´ä»½ç»Ÿè®¡
            year = paper.get('year', 'unknown')
            quality_stats['by_year'][str(year)] = quality_stats['by_year'].get(str(year), 0) + 1
            
            # é«˜å½±å“æœŸåˆŠ
            if paper.get('quality_indicators', {}).get('impact_factor', 0) >= 8.0:
                journal = paper.get('venue', '')
                if journal and journal not in quality_stats['high_impact_journals']:
                    quality_stats['high_impact_journals'].append(journal)
        
        return quality_stats
    
    def _generate_readme_changes(self, papers: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”ŸæˆREADMEå˜æ›´é¢„è§ˆ"""
        changes = {
            'sections_to_add': [],
            'papers_by_category': {},
            'new_categories': [],
            'toc_updates': []
        }
        
        # æŒ‰ä¸»é¢˜å’Œå¹´ä»½åˆ†ç»„è®ºæ–‡
        for paper in papers:
            year = str(paper.get('year', '2025'))
            categories = self._classify_paper(paper)
            
            for category in categories:
                if category not in changes['papers_by_category']:
                    changes['papers_by_category'][category] = {}
                
                if year not in changes['papers_by_category'][category]:
                    changes['papers_by_category'][category][year] = []
                
                changes['papers_by_category'][category][year].append(self._format_paper_entry(paper))
        
        # è¯†åˆ«æ–°åˆ†ç±»
        existing_categories = self._get_existing_categories()
        new_categories = set(changes['papers_by_category'].keys()) - existing_categories
        changes['new_categories'] = list(new_categories)
        
        return changes
    
    def _classify_paper(self, paper: Dict[str, Any]) -> List[str]:
        """åˆ†ç±»è®ºæ–‡åˆ°åˆé€‚çš„ä¸»é¢˜"""
        categories = []
        
        title = paper.get('title', '').lower()
        abstract = paper.get('abstract', '').lower()
        keywords = [kw.lower() for kw in paper.get('keywords', [])]
        
        text_content = f"{title} {abstract} {' '.join(keywords)}"
        
        # åŸºäºå…³é”®è¯çš„åˆ†ç±»è§„åˆ™
        classification_rules = {
            'explainability': [
                'explainable', 'interpretable', 'interpretability', 'xai', 
                'explainable ai', 'shap', 'lime', 'attention'
            ],
            'llm-applications': [
                'large language model', 'llm', 'gpt', 'bert', 'transformer',
                'natural language', 'chatgpt', 'language model'
            ],
            'knowledge-graph': [
                'knowledge graph', 'kg', 'ontology', 'semantic network',
                'graph neural network', 'graph embedding'
            ],
            'fault-diagnosis': [
                'fault diagnosis', 'fault detection', 'failure diagnosis',
                'anomaly detection', 'fault classification'
            ],
            'predictive-maintenance': [
                'predictive maintenance', 'prognostics', 'remaining useful life',
                'rul', 'health monitoring', 'condition monitoring'
            ],
            'deep-learning': [
                'deep learning', 'neural network', 'cnn', 'lstm', 'rnn',
                'autoencoder', 'generative adversarial'
            ]
        }
        
        for category, keywords_list in classification_rules.items():
            if any(keyword in text_content for keyword in keywords_list):
                categories.append(category)
        
        # è‡³å°‘åˆ†é…ä¸€ä¸ªé€šç”¨ç±»åˆ«
        if not categories:
            categories.append('general-phm')
        
        return categories
    
    def _format_paper_entry(self, paper: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–è®ºæ–‡æ¡ç›®ä¸ºAwesomeåˆ—è¡¨æ ¼å¼"""
        title = paper.get('title', 'Unknown Title')
        authors = paper.get('authors', [])
        venue = paper.get('venue', 'Unknown Venue')
        year = paper.get('year', '')
        doi = paper.get('doi', '')
        
        # æ ¼å¼åŒ–ä½œè€…
        if len(authors) > 3:
            author_str = f"{authors[0]} et al."
        else:
            author_str = ", ".join(authors)
        
        # æ„å»ºåŸºæœ¬æ¡ç›®
        entry = f"- **[{title}]"
        
        # æ·»åŠ é“¾æ¥
        if doi:
            entry += f"(https://doi.org/{doi})"
        else:
            entry += "(#)"  # å ä½ç¬¦
        
        # æ·»åŠ å…ƒæ•°æ®
        entry += f"** - {author_str} ({venue}, {year})"
        
        # æ·»åŠ è´¨é‡æŒ‡æ ‡
        quality_tier = paper.get('quality_tier', '')
        if quality_tier == 'top_tier':
            entry += " ğŸ†"
        elif quality_tier == 'excellent':
            entry += " â­"
        
        # æ·»åŠ PDFå’Œä»£ç é“¾æ¥å ä½ç¬¦
        entry += " [[PDF](#)] [[Code](#)] [[BibTeX](#)]"
        
        # æ·»åŠ ç®€çŸ­æè¿°
        abstract = paper.get('abstract', '')
        if abstract:
            # æå–ç¬¬ä¸€å¥ä½œä¸ºç®€çŸ­æè¿°
            first_sentence = abstract.split('.')[0]
            if len(first_sentence) > 100:
                first_sentence = first_sentence[:97] + "..."
            entry += f"\n  - {first_sentence}"
        
        return entry
    
    def _get_existing_categories(self) -> set:
        """è·å–ç°æœ‰çš„è®ºæ–‡åˆ†ç±»"""
        # ä»å½“å‰READMEæˆ–é…ç½®ä¸­è¯»å–ç°æœ‰åˆ†ç±»
        existing_categories = {
            'fault-diagnosis', 'predictive-maintenance', 'deep-learning',
            'digital-twin', 'rul-prediction'
        }
        return existing_categories
    
    def _generate_data_changes(self, papers: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆæ•°æ®æ–‡ä»¶å˜æ›´é¢„è§ˆ"""
        changes = {
            'new_files': [],
            'updated_files': [],
            'bibtex_entries': len(papers),
            'abstract_files': len([p for p in papers if p.get('abstract')]),
            'quality_records': len(papers)
        }
        
        for paper in papers:
            paper_id = paper.get('id', '')
            if paper_id:
                # æ–°å¢çš„æ•°æ®æ–‡ä»¶
                changes['new_files'].extend([
                    f"data/papers/{paper_id}.json",
                    f"data/bibtex/{paper_id}.bib"
                ])
                
                if paper.get('abstract'):
                    changes['new_files'].append(f"data/abstracts/{paper_id}.txt")
        
        return changes
    
    def _save_proposal(self, proposal: UpdateProposal, context: Optional[Dict[str, Any]] = None):
        """ä¿å­˜ææ¡ˆåˆ°æ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"proposal_{timestamp}.json"
        filepath = self.data_dir / "proposals" / filename
        
        proposal_data = proposal.to_dict()
        if context:
            proposal_data['search_context'] = context
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(proposal_data, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"ææ¡ˆå·²ä¿å­˜åˆ°: {filepath}")
    
    def display_proposal(self, proposal: UpdateProposal) -> None:
        """æ˜¾ç¤ºæ›´æ–°ææ¡ˆç»™ç”¨æˆ·"""
        print("\n" + "="*80)
        print("ğŸ“‹ APPAæ›´æ–°ææ¡ˆ - æ–°å‘ç°çš„è®ºæ–‡")
        print("="*80)
        
        # æ€»ä½“ç»Ÿè®¡
        stats = proposal.quality_summary
        print(f"\nğŸ“Š å‘ç°è®ºæ–‡: {stats['total_papers']} ç¯‡")
        print(f"ğŸ† è´¨é‡åˆ†å¸ƒ: "
              f"é¡¶çº§({stats['by_tier']['top_tier']}) | "
              f"ä¼˜ç§€({stats['by_tier']['excellent']}) | "
              f"è‰¯å¥½({stats['by_tier']['good']}) | "
              f"å¾…è¯„ä¼°({stats['by_tier']['under_review']})")
        
        # æŒ‰åˆ†ç±»æ˜¾ç¤ºè®ºæ–‡
        print(f"\nğŸ“š è®ºæ–‡åˆ†ç±»é¢„è§ˆ:")
        for category, years_data in proposal.readme_changes['papers_by_category'].items():
            print(f"\n### {category.replace('-', ' ').title()}")
            for year, papers in years_data.items():
                print(f"  ğŸ“… {year} ({len(papers)} ç¯‡):")
                for paper_entry in papers[:3]:  # åªæ˜¾ç¤ºå‰3ç¯‡
                    # ç®€åŒ–æ˜¾ç¤º
                    title_line = paper_entry.split('\n')[0]
                    title = title_line.split('**[')[1].split(']')[0] if '**[' in title_line else "Unknown"
                    print(f"    - {title[:60]}{'...' if len(title) > 60 else ''}")
                
                if len(papers) > 3:
                    print(f"    - ... è¿˜æœ‰ {len(papers) - 3} ç¯‡")
        
        # æ•°æ®æ–‡ä»¶å˜æ›´
        data_changes = proposal.data_changes
        print(f"\nğŸ’¾ æ•°æ®æ–‡ä»¶å˜æ›´:")
        print(f"  - æ–°å¢JSONæ–‡ä»¶: {len(data_changes['new_files'])} ä¸ª")
        print(f"  - BibTeXæ¡ç›®: {data_changes['bibtex_entries']} ä¸ª")
        print(f"  - æ‘˜è¦æ–‡ä»¶: {data_changes['abstract_files']} ä¸ª")
        
        print("\n" + "="*80)
    
    def get_user_confirmation(self, proposal: UpdateProposal) -> Tuple[bool, List[str]]:
        """
        è·å–ç”¨æˆ·ç¡®è®¤
        
        Returns:
            Tuple[bool, List[str]]: (æ˜¯å¦ç¡®è®¤, é€‰æ‹©çš„è®ºæ–‡IDåˆ—è¡¨)
        """
        self.display_proposal(proposal)
        
        print("\nâ“ ç¡®è®¤æ“ä½œ:")
        print("1. å…¨éƒ¨æ·»åŠ åˆ°Awesomeåˆ—è¡¨")
        print("2. é€‰æ‹©æ€§æ·»åŠ ")
        print("3. æš‚ä¸æ·»åŠ ï¼Œä¿å­˜ææ¡ˆ")
        print("4. å–æ¶ˆ")
        
        while True:
            choice = input("\nè¯·é€‰æ‹© (1-4): ").strip()
            
            if choice == "1":
                # å…¨éƒ¨æ·»åŠ 
                paper_ids = [paper.get('id') for paper in proposal.new_papers if paper.get('id')]
                return True, paper_ids
            
            elif choice == "2":
                # é€‰æ‹©æ€§æ·»åŠ 
                print("\nğŸ“‹ å¯é€‰è®ºæ–‡åˆ—è¡¨:")
                for i, paper in enumerate(proposal.new_papers):
                    title = paper.get('title', 'Unknown')[:50]
                    quality = paper.get('quality_tier', 'unknown')
                    print(f"{i+1:2d}. {title}{'...' if len(paper.get('title', '')) > 50 else ''} ({quality})")
                
                selected_indices = input("\nè¯·è¾“å…¥è®ºæ–‡åºå· (ç”¨é€—å·åˆ†éš”, å¦‚: 1,3,5): ").strip()
                try:
                    indices = [int(x.strip()) - 1 for x in selected_indices.split(',') if x.strip()]
                    selected_papers = [proposal.new_papers[i].get('id') for i in indices 
                                     if 0 <= i < len(proposal.new_papers)]
                    return True, [pid for pid in selected_papers if pid]
                except (ValueError, IndexError):
                    print("âŒ æ— æ•ˆçš„åºå·æ ¼å¼ï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue
            
            elif choice == "3":
                # ä¿å­˜ä½†ä¸åº”ç”¨
                print("ğŸ’¾ ææ¡ˆå·²ä¿å­˜ï¼Œç¨åå¯é€šè¿‡ scripts/awesome_tools.sh ç®¡ç†")
                return False, []
            
            elif choice == "4":
                # å–æ¶ˆ
                print("âŒ æ“ä½œå·²å–æ¶ˆ")
                return False, []
            
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def apply_updates(self, proposal: UpdateProposal, selected_paper_ids: List[str]) -> Dict[str, Any]:
        """
        åº”ç”¨ç”¨æˆ·ç¡®è®¤çš„æ›´æ–°
        
        Args:
            proposal: æ›´æ–°ææ¡ˆ
            selected_paper_ids: ç”¨æˆ·é€‰æ‹©çš„è®ºæ–‡IDåˆ—è¡¨
        
        Returns:
            Dict: åº”ç”¨ç»“æœ
        """
        if not selected_paper_ids:
            return {'success': False, 'message': 'æ²¡æœ‰é€‰æ‹©ä»»ä½•è®ºæ–‡'}
        
        self.logger.info(f"åº”ç”¨æ›´æ–°ï¼ŒåŒ…å« {len(selected_paper_ids)} ç¯‡è®ºæ–‡")
        
        # è¿‡æ»¤é€‰ä¸­çš„è®ºæ–‡
        selected_papers = [
            paper for paper in proposal.new_papers 
            if paper.get('id') in selected_paper_ids
        ]
        
        results = {
            'success': True,
            'papers_added': len(selected_papers),
            'files_created': [],
            'readme_updated': False,
            'errors': []
        }
        
        try:
            # 1. ä¿å­˜è®ºæ–‡è¯¦ç»†æ•°æ®åˆ°data/
            self._save_paper_data(selected_papers, results)
            
            # 2. æ›´æ–°README.md
            self._update_readme(selected_papers, results)
            
            # 3. æ›´æ–°ç»Ÿè®¡æ–‡ä»¶
            self._update_statistics(selected_papers, results)
            
            self.logger.info(f"æ›´æ–°åº”ç”¨æˆåŠŸ: {results['papers_added']} ç¯‡è®ºæ–‡")
            
        except Exception as e:
            self.logger.error(f"åº”ç”¨æ›´æ–°æ—¶å‡ºé”™: {e}")
            results['success'] = False
            results['errors'].append(str(e))
        
        return results
    
    def _save_paper_data(self, papers: List[Dict[str, Any]], results: Dict[str, Any]) -> None:
        """ä¿å­˜è®ºæ–‡è¯¦ç»†æ•°æ®"""
        for paper in papers:
            paper_id = paper.get('id')
            if not paper_id:
                continue
            
            # ä¿å­˜JSONæ ¼å¼çš„è®ºæ–‡è¯¦æƒ…
            json_path = self.data_dir / "papers" / f"{paper_id}.json"
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(paper, f, indent=2, ensure_ascii=False)
            results['files_created'].append(str(json_path))
            
            # ä¿å­˜BibTeX
            bibtex_content = paper.get('bibtex', '')
            if bibtex_content:
                bib_path = self.data_dir / "bibtex" / f"{paper_id}.bib"
                with open(bib_path, 'w', encoding='utf-8') as f:
                    f.write(bibtex_content)
                results['files_created'].append(str(bib_path))
            
            # ä¿å­˜æ‘˜è¦
            abstract = paper.get('abstract', '')
            if abstract:
                abstract_path = self.data_dir / "abstracts" / f"{paper_id}.txt"
                with open(abstract_path, 'w', encoding='utf-8') as f:
                    f.write(abstract)
                results['files_created'].append(str(abstract_path))
    
    def _update_readme(self, papers: List[Dict[str, Any]], results: Dict[str, Any]) -> None:
        """æ›´æ–°README.mdä¸ºAwesomeæ ¼å¼"""
        readme_path = self.project_root / "README.md"
        
        if not readme_path.exists():
            # åˆ›å»ºæ–°çš„Awesomeæ ¼å¼README
            self._create_awesome_readme(papers)
        else:
            # æ›´æ–°ç°æœ‰README
            self._append_to_awesome_readme(papers)
        
        results['readme_updated'] = True
    
    def _create_awesome_readme(self, papers: List[Dict[str, Any]]) -> None:
        """åˆ›å»ºæ–°çš„Awesomeæ ¼å¼README"""
        content = self._generate_awesome_readme_content(papers)
        
        readme_path = self.project_root / "README.md"
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def _append_to_awesome_readme(self, papers: List[Dict[str, Any]]) -> None:
        """å‘ç°æœ‰READMEæ·»åŠ æ–°è®ºæ–‡"""
        readme_path = self.project_root / "README.md"
        
        # è¯»å–ç°æœ‰å†…å®¹
        with open(readme_path, 'r', encoding='utf-8') as f:
            current_content = f.read()
        
        # ç”Ÿæˆæ–°æ¡ç›®
        new_entries = self._generate_paper_entries(papers)
        
        # æ’å…¥åˆ°åˆé€‚ä½ç½®ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œè¿½åŠ åˆ°æ–‡ä»¶æœ«å°¾ï¼‰
        updated_content = current_content + "\n\n" + new_entries
        
        # å†™å›æ–‡ä»¶
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(updated_content)
    
    def _generate_awesome_readme_content(self, papers: List[Dict[str, Any]]) -> str:
        """ç”ŸæˆAwesomeæ ¼å¼çš„READMEå†…å®¹"""
        current_year = datetime.now().year
        
        content = f"""# Awesome PHM Papers [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

> ç²¾é€‰çš„PHM(Prognostics and Health Management)é¢†åŸŸé«˜è´¨é‡å­¦æœ¯è®ºæ–‡åˆ—è¡¨

## Contents

- [2025](#2025)
  - [å¯è§£é‡Šæ€§ä¸æ•…éšœè¯Šæ–­](#explainability-and-fault-diagnosis)
  - [å¤§è¯­è¨€æ¨¡å‹åº”ç”¨](#llm-applications)
- [2024](#2024)
  - [çŸ¥è¯†å›¾è°±èåˆ](#knowledge-graph-fusion)
  - [æ·±åº¦å­¦ä¹ æ–¹æ³•](#deep-learning-methods)
- [æŒ‰ä¸»é¢˜åˆ†ç±»](#topics)
- [è´¡çŒ®æŒ‡å—](#contributing)
- [è®¸å¯è¯](#license)

---

## {current_year}

### Explainability and Fault Diagnosis

"""
        
        # æ·»åŠ è®ºæ–‡æ¡ç›®
        content += self._generate_paper_entries(papers)
        
        content += """

---

## Topics

### Deep Learning for PHM
- [æ·±åº¦å­¦ä¹ åœ¨PHMä¸­çš„åº”ç”¨](data/topics/deep-learning.md)

### Fault Diagnosis
- [æ•…éšœè¯Šæ–­æ–¹æ³•](data/topics/fault-diagnosis.md)

### Predictive Maintenance
- [é¢„æµ‹æ€§ç»´æŠ¤æŠ€æœ¯](data/topics/predictive-maintenance.md)

---

## Contributing

æ¬¢è¿è´¡çŒ®! è¯·é˜…è¯» [è´¡çŒ®æŒ‡å—](CONTRIBUTING.md) äº†è§£å¦‚ä½•æ·»åŠ æ–°è®ºæ–‡ã€‚

### è®ºæ–‡è´¨é‡è¦æ±‚
- å‘è¡¨åœ¨çŸ¥åæœŸåˆŠæˆ–ä¼šè®® (å½±å“å› å­ â‰¥ 5.0)
- ä¸PHMé¢†åŸŸé«˜åº¦ç›¸å…³
- æ’é™¤MDPIç­‰ä½è´¨é‡å‡ºç‰ˆå•†

### æ·»åŠ è®ºæ–‡æ­¥éª¤
1. Forkæœ¬ä»“åº“
2. æ·»åŠ è®ºæ–‡åˆ°å¯¹åº”åˆ†ç±»
3. æ›´æ–°ç›¸å…³æ•°æ®æ–‡ä»¶
4. æäº¤Pull Request

---

## License

[![CC0](https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0)

This work is licensed under a [Creative Commons Zero v1.0 Universal](https://creativecommons.org/publicdomain/zero/1.0) License.
"""
        
        return content
    
    def _generate_paper_entries(self, papers: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆè®ºæ–‡æ¡ç›®"""
        entries_by_category = {}
        
        for paper in papers:
            categories = self._classify_paper(paper)
            for category in categories:
                if category not in entries_by_category:
                    entries_by_category[category] = []
                entries_by_category[category].append(self._format_paper_entry(paper))
        
        content = ""
        for category, entries in entries_by_category.items():
            category_title = category.replace('-', ' ').title()
            content += f"\n#### {category_title}\n\n"
            for entry in entries:
                content += entry + "\n"
        
        return content
    
    def _update_statistics(self, papers: List[Dict[str, Any]], results: Dict[str, Any]) -> None:
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        stats_path = self.data_dir / "statistics" / "overview.json"
        
        # è¯»å–ç°æœ‰ç»Ÿè®¡
        if stats_path.exists():
            with open(stats_path, 'r', encoding='utf-8') as f:
                stats = json.load(f)
        else:
            stats = {
                'total_papers': 0,
                'by_year': {},
                'by_category': {},
                'by_quality_tier': {},
                'last_updated': datetime.now().isoformat()
            }
        
        # æ›´æ–°ç»Ÿè®¡
        stats['total_papers'] += len(papers)
        stats['last_updated'] = datetime.now().isoformat()
        
        for paper in papers:
            year = str(paper.get('year', '2025'))
            quality_tier = paper.get('quality_tier', 'under_review')
            categories = self._classify_paper(paper)
            
            # å¹´ä»½ç»Ÿè®¡
            stats['by_year'][year] = stats['by_year'].get(year, 0) + 1
            
            # è´¨é‡åˆ†çº§ç»Ÿè®¡
            stats['by_quality_tier'][quality_tier] = stats['by_quality_tier'].get(quality_tier, 0) + 1
            
            # åˆ†ç±»ç»Ÿè®¡
            for category in categories:
                stats['by_category'][category] = stats['by_category'].get(category, 0) + 1
        
        # ä¿å­˜ç»Ÿè®¡
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        results['files_created'].append(str(stats_path))


def main():
    """æµ‹è¯•ç”¨ä¾‹"""
    # ç¤ºä¾‹è®ºæ–‡æ•°æ®
    sample_papers = [
        {
            'id': '2025-MSSP-Zhang-Explainable',
            'title': 'Explainable Fault Diagnosis Using Attention-based Deep Learning',
            'authors': ['Zhang Wei', 'Liu Ming'],
            'year': 2025,
            'venue': 'Mechanical Systems and Signal Processing',
            'doi': '10.1016/j.ymssp.2025.001',
            'abstract': 'This paper proposes an explainable fault diagnosis method using attention mechanisms.',
            'quality_tier': 'excellent',
            'quality_indicators': {'impact_factor': 8.4}
        }
    ]
    
    # åˆ›å»ºæ›´æ–°ç®¡ç†å™¨
    update_manager = UpdateManager()
    
    # ç”Ÿæˆææ¡ˆ
    proposal = update_manager.generate_proposal(sample_papers)
    
    # æ˜¾ç¤ºææ¡ˆ
    update_manager.display_proposal(proposal)
    
    # æ¨¡æ‹Ÿç”¨æˆ·ç¡®è®¤
    confirmed, selected_ids = update_manager.get_user_confirmation(proposal)
    
    if confirmed and selected_ids:
        results = update_manager.apply_updates(proposal, selected_ids)
        print(f"\nâœ… æ›´æ–°å®Œæˆ: {results}")


if __name__ == "__main__":
    main()